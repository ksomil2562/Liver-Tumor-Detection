{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a93e51d-a187-4ea5-a00a-17975ead589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import first\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from monai.losses import DiceLoss\n",
    "from tqdm import tqdm\n",
    "\n",
    "def dice_metric(predicted, target):\n",
    "    '''\n",
    "    In this function we take `predicted` and `target` (label) to calculate the dice coefficient then we use it \n",
    "    to calculate a metric value for the training and the validation.\n",
    "    '''\n",
    "    dice_value = DiceLoss(to_onehot_y=True, sigmoid=True, squared_pred=True)\n",
    "    value = 1 - dice_value(predicted, target).item()\n",
    "    return value\n",
    "\n",
    "def calculate_weights(val1, val2):\n",
    "    '''\n",
    "    In this function we take the number of the background and the foreground pixels to return the `weights` \n",
    "    for the cross entropy loss values.\n",
    "    '''\n",
    "    count = np.array([val1, val2])\n",
    "    summ = count.sum()\n",
    "    weights = count/summ\n",
    "    weights = 1/weights\n",
    "    summ = weights.sum()\n",
    "    weights = weights/summ\n",
    "    return torch.tensor(weights, dtype=torch.float32)\n",
    "\n",
    "def train(model, data_in, loss, optim, max_epochs, model_dir, test_interval=1 , device=torch.device(\"cpu\")):\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    save_loss_train = []\n",
    "    save_loss_test = []\n",
    "    save_metric_train = []\n",
    "    save_metric_test = []\n",
    "    train_loader, test_loader = data_in\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "        model.train()\n",
    "        train_epoch_loss = 0\n",
    "        train_step = 0\n",
    "        epoch_metric_train = 0\n",
    "        for batch_data in train_loader:\n",
    "            \n",
    "            train_step += 1\n",
    "\n",
    "            volume = batch_data[\"vol\"]\n",
    "            label = batch_data[\"seg\"]\n",
    "            label = label != 0\n",
    "            volume, label = (volume.to(device), label.to(device))\n",
    "\n",
    "            optim.zero_grad()\n",
    "            outputs = model(volume)\n",
    "            \n",
    "            train_loss = loss(outputs, label)\n",
    "            \n",
    "            train_loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            train_epoch_loss += train_loss.item()\n",
    "            print(\n",
    "                f\"{train_step}/{len(train_loader) // train_loader.batch_size}, \"\n",
    "                f\"Train_loss: {train_loss.item():.4f}\")\n",
    "\n",
    "            train_metric = dice_metric(outputs, label)\n",
    "            epoch_metric_train += train_metric\n",
    "            print(f'Train_dice: {train_metric:.4f}')\n",
    "\n",
    "        print('-'*20)\n",
    "        \n",
    "        train_epoch_loss /= train_step\n",
    "        print(f'Epoch_loss: {train_epoch_loss:.4f}')\n",
    "        save_loss_train.append(train_epoch_loss)\n",
    "        np.save(os.path.join(model_dir, 'loss_train.npy'), save_loss_train)\n",
    "        \n",
    "        epoch_metric_train /= train_step\n",
    "        print(f'Epoch_metric: {epoch_metric_train:.4f}')\n",
    "\n",
    "        save_metric_train.append(epoch_metric_train)\n",
    "        np.save(os.path.join(model_dir, 'metric_train.npy'), save_metric_train)\n",
    "\n",
    "        if (epoch + 1) % test_interval == 0:\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                test_epoch_loss = 0\n",
    "                test_metric = 0\n",
    "                epoch_metric_test = 0\n",
    "                test_step = 0\n",
    "\n",
    "                for test_data in test_loader:\n",
    "\n",
    "                    test_step += 1\n",
    "\n",
    "                    test_volume = test_data[\"vol\"]\n",
    "                    test_label = test_data[\"seg\"]\n",
    "                    test_label = test_label != 0\n",
    "                    test_volume, test_label = (test_volume.to(device), test_label.to(device),)\n",
    "                    \n",
    "                    test_outputs = model(test_volume)\n",
    "                    \n",
    "                    test_loss = loss(test_outputs, test_label)\n",
    "                    test_epoch_loss += test_loss.item()\n",
    "                    test_metric = dice_metric(test_outputs, test_label)\n",
    "                    epoch_metric_test += test_metric\n",
    "    \n",
    "                test_epoch_loss /= test_step\n",
    "                print(f'test_loss_epoch: {test_epoch_loss:.4f}')\n",
    "                save_loss_test.append(test_epoch_loss)\n",
    "                np.save(os.path.join(model_dir, 'loss_test.npy'), save_loss_test)\n",
    "\n",
    "                epoch_metric_test /= test_step\n",
    "                print(f'test_dice_epoch: {epoch_metric_test:.4f}')\n",
    "                save_metric_test.append(epoch_metric_test)\n",
    "                np.save(os.path.join(model_dir, 'metric_test.npy'), save_metric_test)\n",
    "\n",
    "                if epoch_metric_test > best_metric:\n",
    "                    best_metric = epoch_metric_test\n",
    "                    best_metric_epoch = epoch + 1\n",
    "                    torch.save(model.state_dict(), os.path.join(\n",
    "                        model_dir, \"best_metric_model.pth\"))\n",
    "                \n",
    "                print(\n",
    "                    f\"current epoch: {epoch + 1} current mean dice: {test_metric:.4f}\"\n",
    "                    f\"\\nbest mean dice: {best_metric:.4f} \"\n",
    "                    f\"at epoch: {best_metric_epoch}\"\n",
    "                )\n",
    "\n",
    "\n",
    "    print(\n",
    "        f\"train completed, best_metric: {best_metric:.4f} \"\n",
    "        f\"at epoch: {best_metric_epoch}\")\n",
    "\n",
    "\n",
    "def show_patient(data, SLICE_NUMBER=1, train=True, test=False):\n",
    "    \"\"\"\n",
    "    This function is to show one patient from your datasets, so that you can si if the it is okay or you need \n",
    "    to change/delete something.\n",
    "\n",
    "    `data`: this parameter should take the patients from the data loader, which means you need to can the function\n",
    "    prepare first and apply the transforms that you want after that pass it to this function so that you visualize \n",
    "    the patient with the transforms that you want.\n",
    "    `SLICE_NUMBER`: this parameter will take the slice number that you want to display/show\n",
    "    `train`: this parameter is to say that you want to display a patient from the training data (by default it is true)\n",
    "    `test`: this parameter is to say that you want to display a patient from the testing patients.\n",
    "    \"\"\"\n",
    "\n",
    "    check_patient_train, check_patient_test = data\n",
    "\n",
    "    view_train_patient = first(check_patient_train)\n",
    "    view_test_patient = first(check_patient_test)\n",
    "\n",
    "    \n",
    "    if train:\n",
    "        plt.figure(\"Visualization Train\", (12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(f\"vol {SLICE_NUMBER}\")\n",
    "        plt.imshow(view_train_patient[\"vol\"][0, 0, :, :, SLICE_NUMBER], cmap=\"gray\")\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(f\"seg {SLICE_NUMBER}\")\n",
    "        plt.imshow(view_train_patient[\"seg\"][0, 0, :, :, SLICE_NUMBER])\n",
    "        plt.show()\n",
    "    \n",
    "    if test:\n",
    "        plt.figure(\"Visualization Test\", (12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(f\"vol {SLICE_NUMBER}\")\n",
    "        plt.imshow(view_test_patient[\"vol\"][0, 0, :, :, SLICE_NUMBER], cmap=\"gray\")\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(f\"seg {SLICE_NUMBER}\")\n",
    "        plt.imshow(view_test_patient[\"seg\"][0, 0, :, :, SLICE_NUMBER])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def calculate_pixels(data):\n",
    "    val = np.zeros((1, 2))\n",
    "\n",
    "    for batch in tqdm(data):\n",
    "        batch_label = batch[\"seg\"] != 0\n",
    "        _, count = np.unique(batch_label, return_counts=True)\n",
    "\n",
    "        if len(count) == 1:\n",
    "            count = np.append(count, 0)\n",
    "        val += count\n",
    "\n",
    "    print('The last values:', val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8defb5-d95c-41d4-a68e-345809cd96d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
